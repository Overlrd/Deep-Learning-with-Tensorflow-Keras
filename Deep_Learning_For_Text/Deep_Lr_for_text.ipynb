{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Some NLP tasks :\n",
        "\n",
        " - “What’s the topic of this text?” (text classification)\n",
        " - “Does this text contain abuse?” (content filtering)\n",
        " - “Does this text sound positive or negative?” (sentiment analysis)\n",
        " - “What should be the next word in this incomplete sentence?” (language modeling)\n",
        " - “How would you say this in German?” (translation)\n",
        " - “How would you summarize this article in one paragraph?” (summarization)"
      ],
      "metadata": {
        "id": "F-_1IXc8ssGQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Of course, keep in mind throughout this chapter that the text-processing models you\n",
        "will train won’t possess a human-like understanding of language; rather, they simply\n",
        "look for statistical regularities in their input data, which turns out to be sufficient to\n",
        "perform well on many simple tasks. In much the same way that computer vision is pat-\n",
        "tern recognition applied to pixels, NLP is pattern recognition applied to words, sen-\n",
        "tences, and paragraphs."
      ],
      "metadata": {
        "id": "Sh7PzIlTs1S9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preparing text data\n",
        "\n",
        "\n",
        "Deep learning models, being differentiable functions, can only process numeric ten-\n",
        "sors: they can’t take raw text as input. Vectorizing text is the process of transforming\n",
        "text into numeric tensors. Text vectorization processes come in many shapes and\n",
        "forms, but they all follow the same template :\n",
        "\n",
        " - First, you standardize the text to make it easier to process, such as by converting\n",
        "it to lowercase or removing punctuation.\n",
        " - You split the text into units (called tokens), such as characters, words, or groups\n",
        "of words. This is called tokenization.\n",
        " -  You convert each such token into a numeric"
      ],
      "metadata": {
        "id": "ocwKITtdtZhr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![image.png](data:image/png;base64,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)"
      ],
      "metadata": {
        "id": "_yESamHItrnH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Text standardization\n"
      ],
      "metadata": {
        "id": "MOOLcHBV09S2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "Consider these two sentences:\n",
        "\n",
        " - “sunset came. i was staring at the Mexico sky. Isnt nature splendid??”\n",
        " - “Sunset came; I stared at the México sky. Isn’t nature splendid?”\n",
        "\n",
        " Text standardization is a basic form of feature engineering that aims to erase\n",
        "encoding differences that you don’t want your model to have to deal with. It’s not\n",
        "exclusive to machine learning, either—you’d have to do the same thing if you were\n",
        "building a search engine.\n",
        "\n",
        "\n",
        " - One of the simplest and most widespread standardization schemes is “convert to\n",
        "lowercase and remove punctuation characters.” Our two sentences would become :   \n",
        "  - “sunset came i was staring at the mexico sky isnt nature splendid”\n",
        "  - “sunset came i stared at the méxico sky isnt nature splendid”\n",
        "\n",
        "\n",
        " - Another common transformation is to convert special characters\n",
        "to a standard form, such as replacing “é” with “e,” “æ” with “ae,” and so on. Our token\n",
        "“méxico” would then become “mexico”.\n",
        "\n",
        "\n",
        " - Lastly, a much more advanced standardization pattern that is more rarely used in a\n",
        "machine learning context is stemming: converting variations of a term (such as differ-\n",
        "ent conjugated forms of a verb) into a single shared representation, like turning\n",
        "“caught” and “been catching” into “[catch]” or “cats” into “[cat]”. With stemming,\n",
        "“was staring” and “stared” would become something like “[stare]”, and our two similar\n",
        "sentences would finally end up with an identical encoding:\n",
        "  - “sunset came i [stare] at the mexico sky isnt nature splendid”\n",
        "\n",
        "Of course, standardization may\n",
        "also erase some amount of information, so always keep the context in mind.\n"
      ],
      "metadata": {
        "id": "Q7WHHD0ct2Vd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Text splitting (tokenization)\n"
      ],
      "metadata": {
        "id": "CqBEiEYk0_w4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Once your text is standardized, you need to break it up into units to be vectorized\n",
        "(tokens), a step called tokenization. You could do this in three different ways:\n",
        "\n",
        " - Word-level tokenization —Where tokens are space-separated (or punctuation-\n",
        "separated) substrings. A variant of this is to further split words into subwords\n",
        "when applicable—for instance, treating “staring” as “star+ing” or “called” as\n",
        "“call+ed.”\n",
        " - N-gram tokenization—Where tokens are groups of N consecutive words. For\n",
        "instance, “the cat” or “he was” would be 2-gram tokens (also called bigrams).\n",
        " - Character-level tokenization—Where each character is its own token. In practice,\n",
        "this scheme is rarely used, and you only really see it in specialized contexts, like\n",
        "text generation or speech recognition.\n",
        "\n",
        "\n",
        "There are two\n",
        "kinds of text-processing models: those that care about word order, called **sequence models,** and those that treat input words as a set, discarding their original order, called\n",
        "**bag-of-words models**. If you’re building a **sequence model**, you’ll use word-level tokeni-\n",
        "zation, and if you’re building a **bag-of-words model**, you’ll use N-gram tokenization."
      ],
      "metadata": {
        "id": "pveWzulivfx_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Vocabulary Indexing\n"
      ],
      "metadata": {
        "id": "_pmiovlM03Lg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Once your text is split into tokens, you need to encode each token into a numerical\n",
        "representation.\n",
        "\n",
        "\n",
        "the way you’d go about it is to build\n",
        "an index of all terms found in the training data (the “vocabulary”), and assign a\n",
        "unique integer to each entry in the vocabulary.\n",
        "\n",
        "Something like this:\n",
        "```python\n",
        "\n",
        "vocabulary = {}\n",
        "for text in dataset:\n",
        "  text = standardize(text)\n",
        "  tokens = tokenize(text)\n",
        "  for token in tokens:\n",
        "    if token not in vocabulary:\n",
        "      vocabulary[token] = len(vocabulary)\n",
        "```\n",
        "\n",
        "You can then convert that integer into a vector encoding that can be processed by a\n",
        "neural network, like a one-hot vector:\n",
        "\n",
        "```python\n",
        "def one_hot_encode_token(token):\n",
        "  vector = np.zeros((len(vocabulary),))\n",
        "  token_index = vocabulary[token]\n",
        "  vector[token_index] = 1\n",
        "  return vector\n",
        "```\n",
        "\n",
        "\n",
        "Note that at this step it’s common to restrict the vocabulary to only the top 20,000 or\n",
        "30,000 most common words found in the training data. Any text dataset tends to fea-\n",
        "ture an extremely large number of unique terms, most of which only show up once or\n",
        "twice—indexing those rare terms would result in an excessively large feature space,\n",
        "where most features would have almost no information content.\n",
        "\n",
        "<br>\n",
        "\n",
        "Your training\n",
        "data may not have contained any instance of the word “cherimoya” (or maybe you\n",
        "excluded it from your index because it was too rare), so doing token_index =\n",
        "vocabulary[\"cherimoya\"] may result in a KeyError. To handle this, you should use\n",
        "an “out of vocabulary” index (abbreviated as OOV index)—a catch-all for any token\n",
        "that wasn’t in the index. It’s usually index 1: you’re actually doing  ```token_index = vocabulary.get(token, 1)```. When decoding a sequence of integers back into words,\n",
        "you’ll replace 1 with something like “[UNK]” (which you’d call an “OOV token”).\n",
        "\n",
        "\n",
        "\n",
        "There are\n",
        "two special tokens that you will commonly use: the OOV token (index 1), and the\n",
        "mask token (index 0).\n",
        "\n",
        "\n",
        "the mask token tells us “ignore me, I’m not a word.” You’d use it in particular to\n",
        "pad sequence data: because data batches need to be contiguous, all sequences in a\n",
        "batch of sequence data must have the same length, so shorter sequences should be\n",
        "padded to the length of the longest sequence. If you want to make a batch of data with\n",
        "the sequences [5, 7, 124, 4, 89] and [8, 34, 21], it would have to look like this:\n",
        "```python\n",
        "[[5, 7, 124, 4, 89]\n",
        "[8, 34, 21, 0, 0]]\n",
        "```"
      ],
      "metadata": {
        "id": "X4T_nbsgxE8r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Using the TextVectorization layer"
      ],
      "metadata": {
        "id": "FMYEisyB1C_w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Python Scratch implementation"
      ],
      "metadata": {
        "id": "PKGeIskp-1xN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import string \n",
        "\n",
        "class Vectorizer:\n",
        "  def standardize(self, text):\n",
        "    # turn text to lower and remove puctuations\n",
        "    text = text.lower()\n",
        "    return \"\".join(char for char in text if char not in string.punctuation)\n",
        "\n",
        "  def tokenize(self, text):\n",
        "    # retrun a list of word-level tokenized words\n",
        "    text = self.standardize(text)\n",
        "    return text.split()\n",
        "\n",
        "  def make_vocabulary(self, dataset):\n",
        "    # add token to vacabulary \n",
        "    self.vocabulary = {\"\":0 , \"[UNK]\" : 1}\n",
        "    for text in dataset:\n",
        "      text = self.standardize(text)\n",
        "      tokens = self.tokenize(text)\n",
        "      for token in tokens:\n",
        "        if token not in self.vocabulary:\n",
        "          self.vocabulary[token] = len(self.vocabulary)\n",
        "\n",
        "    self.inverse_vocabulary = dict ( (v,k) for k,v in self.vocabulary.items())\n",
        "\n",
        "  def encode(self, text):\n",
        "    # encode a token into correspondind vector , 1 if not in vocabulary\n",
        "    text = self.standardize(text)\n",
        "    tokens = self.tokenize(text)\n",
        "    return [self.vocabulary.get(token , 1) for token in tokens]\n",
        "\n",
        "  def decode(self, int_sequences):\n",
        "    # decode a sequence to corresponding words , [UNK] if not in vocabulary\n",
        "    return \" \".join(self.inverse_vocabulary.get(i, \" [UNK] \") for i in int_sequences)\n"
      ],
      "metadata": {
        "id": "oWJILgyG1IFe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer = Vectorizer()"
      ],
      "metadata": {
        "id": "5wJK_K8C8qwA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = [\n",
        "\"I write, erase, rewrite\",\n",
        "\"Erase again, and then\",\n",
        "\"A poppy blooms.\",\n",
        "]"
      ],
      "metadata": {
        "id": "mjMMCMtF8rYr"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer.make_vocabulary(dataset)"
      ],
      "metadata": {
        "id": "wNi7fr2P8uky"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_sentence = \"I write, rewrite, and still rewrite again\"\n",
        "encoded_sentence = vectorizer.encode(test_sentence)\n",
        "print(encoded_sentence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mTs6khUd89NT",
        "outputId": "39526d65-92cb-4195-fde1-e0a4f433b7b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2, 3, 5, 7, 1, 5, 6]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### the Keras TextVectorization layer,"
      ],
      "metadata": {
        "id": "sWju0ExT-860"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import TextVectorization"
      ],
      "metadata": {
        "id": "zeg-ugBy_BUt"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_vecotorization = TextVectorization(output_mode=\"int\")\n",
        "# configure the layer to return integer indices"
      ],
      "metadata": {
        "id": "casQ8pL7_KFd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "By default, the TextVectorization layer will use the setting “convert to lowercase and\n",
        "remove punctuation” for text standardization, and “split on whitespace” for tokeniza-\n",
        "tion. But importantly, you can provide custom functions for standardization and toke-\n",
        "nization, which means the layer is flexible enough to handle any use case."
      ],
      "metadata": {
        "id": "vzf9acf9_jjv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note that\n",
        "such custom functions should operate on tf.string tensors, not regular Python\n",
        "strings! For instance, the default layer behavior is equivalent to the following:"
      ],
      "metadata": {
        "id": "wxppYsSSAKMd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import string\n",
        "import tensorflow as tf\n",
        "\n",
        "def custom_standardization_fn(string_tensor):\n",
        "  lowercase_string = tf.strings.lower(string_tensor)\n",
        "  return tf.strings.regex_replace(lowercase_string, f\"[{re.escape(string.punctuation)}]\", \"\")\n",
        "\n",
        "def custom_split_fn(string_tensor):\n",
        "  return tf.strings.split(string_tensor)"
      ],
      "metadata": {
        "id": "Go2dbLA2_caZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_vectorization = TextVectorization(\n",
        "    output_mode=\"int\",\n",
        "    standardize=custom_standardization_fn,\n",
        "    split=custom_split_fn,\n",
        "    )"
      ],
      "metadata": {
        "id": "UiepjvFw_-pw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Using the TextVectorization layer in a tf.data pipeline or as part of a model"
      ],
      "metadata": {
        "id": "G36n3a1wAzKc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are two ways we could use our TextVectorization layer. The first option is\n",
        "to put it in the tf.data pipeline, like this:\n",
        "```python\n",
        "int_sequence_dataset = string_dataset.map(\n",
        "text_vectorization,\n",
        "num_parallel_calls=4)\n",
        "```\n",
        "\n",
        "\n",
        "The second option is to make it part of the model (after all, it’s a Keras layer), like this:\n",
        "```python\n",
        "text_input = keras.Input(shape=(), dtype=\"string\")\n",
        "vectorized_text = text_vectorization(text_input)\n",
        "embedded_input = keras.layers.Embedding(...)(vectorized_text)\n",
        "output = ...\n",
        "model = keras.Model(text_input, output)\n",
        "```"
      ],
      "metadata": {
        "id": "SaUAOBL3A4CV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "-kixTXGQBggH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "There’s an important difference between the two: if the vectorization step is part of\n",
        "the model, it will happen synchronously with the rest of the model. This means that\n",
        "at each training step, the rest of the model (placed on the GPU) will have to wait for\n",
        "the output of the TextVectorization layer (placed on the CPU) to be ready in order\n",
        "to get to work. Meanwhile, putting the layer in the tf.data pipeline enables you to do asynchronous preprocessing of your data on CPU: while the GPU runs the model\n",
        "on one batch of vectorized data, the CPU stays busy by vectorizing the next batch of\n",
        "raw strings.\n",
        "\n",
        "\n",
        "So if you’re training the model on GPU or TPU, you’ll probably want to go with the first\n",
        "option to get the best performance. This is what we will do in all practical examples\n",
        "throughout this chapter. When training on a CPU, though, synchronous processing is\n",
        "fine: you will get 100% utilization of your cores regardless of which option you go with.\n",
        "\n",
        "\n",
        "Now, if you were to export our model to a production environment, you would want to\n",
        "ship a model that accepts raw strings as input, like in the code snippet for the second\n",
        "option above—otherwise you would have to reimplement text standardization and\n",
        "tokenization in your production environment (maybe in JavaScript?), and you would\n",
        "face the risk of introducing small preprocessing discrepancies that would hurt the\n",
        "model’s accuracy. Thankfully, the TextVectorization layer enables you to include\n",
        "text preprocessing right into your model, making it easier to deploy—even if you were\n",
        "originally using the layer as part of a tf.data pipeline. In the sidebar “Exporting a\n",
        "model that processes raw strings,” you’ll learn how to export an inference-only\n",
        "trained model that incorporates text preprocessing."
      ],
      "metadata": {
        "id": "wnwkn4ONBmkM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "ohfCZCLwB8fa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## modeling"
      ],
      "metadata": {
        "id": "dgleq3NTB-LS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The problem of order in natural language is an interesting one: unlike the steps of\n",
        "a timeseries, words in a sentence don’t have a natural, canonical order. Different lan-\n",
        "guages order similar words in very different ways.\n",
        "\n",
        "Even within a given language, you\n",
        "can typically say the same thing in different ways by reshuffling the words a bit. Even\n",
        "further, if you fully randomize the words in a short sentence, you can still largely fig-\n",
        "ure out what it was saying—though in many cases significant ambiguity seems to arise.\n",
        "\n",
        "Order is clearly important, but its relationship to meaning isn’t straightforward.\n",
        "\n",
        "The simplest thing you could do is just discard order and\n",
        "treat text as an unordered set of words—this gives you bag-of-words models. You could\n",
        "also decide that words should be processed strictly in the order in which they appear,\n",
        "one at a time, like steps in a timeseries.\n",
        "\n",
        "Finally, a hybrid approach is also possible: the Transformer architecture is technically order-agnostic, yet it injects word-position information into\n",
        "the representations it processes, which enables it to simultaneously look at different\n",
        "parts of a sentence (unlike RNNs) while still being order-aware. Because they take into\n",
        "account word order, both RNNs and Transformers are called sequence models."
      ],
      "metadata": {
        "id": "2deOb8BvC8kL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Sequences Models and the IMDB movie reviews data"
      ],
      "metadata": {
        "id": "87OsI9VcC9sU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Let’s start by downloading the dataset from the Stanford page of Andrew Maas and\n",
        "#uncompressing it:\n",
        "\n",
        "!curl -O https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
        "!tar -xf aclImdb_v1.tar.gz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nRas-pDfD5ke",
        "outputId": "46d2bc5e-1de8-4ad6-89ca-7541e12de2f0"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 80.2M  100 80.2M    0     0  31.9M      0  0:00:02  0:00:02 --:--:-- 31.9M\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        " You’re left with a directory named aclImdb, with the following structure:\n",
        "\n",
        "\n",
        "aclImdb/\n",
        "...train/\n",
        "......pos/\n",
        "......neg/\n",
        "...test/\n",
        "......pos/\n",
        "......neg/ \n",
        "\n",
        "\n",
        "For instance, the train/pos/ directory contains a set of 12,500 text files, each of which\n",
        "contains the text body of a positive-sentiment movie review to be used as training data.\n",
        "The negative-sentiment reviews live in the “neg” directories. In total, there are 25,000\n",
        "text files for training and another 25,000 for testing.\n",
        "There’s also a train/unsup subdirectory in there, which we don’t need. Let’s\n",
        "\n",
        "delete it:\n",
        "'''\n",
        "!rm -r aclImdb/train/unsup"
      ],
      "metadata": {
        "id": "GcX1EQuWEEOf"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "''' Take a look at the content of a few of these text files. Whether you’re working with\n",
        "text data or image data, remember to always inspect what your data looks like before\n",
        "you dive into modeling it. It will ground your intuition about what your model is actu-\n",
        "ally doing:\n",
        " '''\n",
        "!cat aclImdb/train/pos/4077_10.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mnfFWlVuEYr2",
        "outputId": "54b0ecb7-23df-49bf-d65d-43f2006b8da0"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I first saw this back in the early 90s on UK TV, i did like it then but i missed the chance to tape it, many years passed but the film always stuck with me and i lost hope of seeing it TV again, the main thing that stuck with me was the end, the hole castle part really touched me, its easy to watch, has a great story, great music, the list goes on and on, its OK me saying how good it is but everyone will take there own best bits away with them once they have seen it, yes the animation is top notch and beautiful to watch, it does show its age in a very few parts but that has now become part of it beauty, i am so glad it has came out on DVD as it is one of my top 10 films of all time. Buy it or rent it just see it, best viewing is at night alone with drink and food in reach so you don't have to stop the film.<br /><br />Enjoy"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Next, let’s prepare a validation set by setting apart 20% of the training text files in a\n",
        "#new directory, aclImdb/val:\n",
        "\n",
        "\n",
        "import os , pathlib , shutil , random\n",
        "\n",
        "base_dir = pathlib.Path(\"aclImdb\")\n",
        "val_dir = base_dir / \"val\"\n",
        "train_dir = base_dir / \"train\"\n",
        "\n",
        "for category in (\"neg\", \"pos\"):\n",
        "  os.makedirs(val_dir / category)\n",
        "  files = os.listdir(train_dir / category)\n",
        "  random.Random(1337).shuffle(files)\n",
        "  num_val_samples = int(0.2 * len(files))\n",
        "  val_files = files[-num_val_samples:]\n",
        "  for fname in val_files:\n",
        "    shutil.move(train_dir / category / fname ,\n",
        "                val_dir / category /fname)\n",
        "\n"
      ],
      "metadata": {
        "id": "_s-HFJrYE1_T"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Let’s create three Dataset objects for training, validation, and testing:\n",
        "\n",
        "\n",
        "from tensorflow import keras\n",
        "batch_size = 32 \n",
        "\n",
        "train_ds = keras.utils.text_dataset_from_directory(\n",
        "\"aclImdb/train\", batch_size=batch_size )\n",
        "\n",
        "val_ds = keras.utils.text_dataset_from_directory(\n",
        "\"aclImdb/val\", batch_size=batch_size\n",
        ")\n",
        "test_ds = keras.utils.text_dataset_from_directory(\n",
        "\"aclImdb/test\", batch_size=batch_size\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ivnNSodFjzX",
        "outputId": "22c4a5ca-a8da-4b92-9501-bf05895fe718"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 20000 files belonging to 2 classes.\n",
            "Found 5000 files belonging to 2 classes.\n",
            "Found 25000 files belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for inputs , targets in train_ds:\n",
        "  print(\"Input shape :\", inputs.shape)\n",
        "  print(\"inputs.dtype:\", inputs.dtype)\n",
        "  print(\"targets.shape:\", targets.shape)\n",
        "  print(\"targets.dtype:\", targets.dtype)\n",
        "  print(\"inputs[0]:\", inputs[0])\n",
        "  print(\"targets[0]:\", targets[0])\n",
        "  break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fS48V7siHBLX",
        "outputId": "37664214-e184-4285-9f91-0f04a48d3b3b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input shape : (32,)\n",
            "inputs.dtype: <dtype: 'string'>\n",
            "targets.shape: (32,)\n",
            "targets.dtype: <dtype: 'int32'>\n",
            "inputs[0]: tf.Tensor(b'In late 1800s San Francisco, poor well-dressed Errol Flynn (as James J. Corbett) works at a bank, and enjoys attending local \"fights\" (boxing) with co-worker and drinking buddy Jack Carson (as Walter Lowrie). One day, pretty Alexis Smith (as Victoria Ware) walks into the \"Comstock Bank\", where Mr. Flynn works. Flynn is so taken with Ms. Smith\\'s elegant beauty, he offers to carry her withdrawal purse. Smith is secretly taken with the handsome Flynn, but is put off by his brashness.<br /><br />Flynn\\'s good deed (actually, pick-up attempt) gets him a complimentary membership in the snooty \"Olympic Club\", which conveniently includes a gymnasium (with boxing equipment). However, Flynn\\'s presumptuous manner, and practical joking (he tickles men on the parallel bars) irritates \"Club\" members. When an English boxing champ visits the club, members endeavor to get Flynn to fight the man. They are hopeful Flynn will resign, humiliated by his defeat - but, Flynn wins! <br /><br />First time producer Robert Buckner puts together a nice package for Warner Brothers, and director Raoul Walsh. Mr. Buckner was, certainly, basking in the success of his contribution (screenplay) to the studio\\'s brilliant \"Yankee Doodle Dandy\". Unfortunately, this story is positively ludicrous. There was a \"Gentleman Jim\" - this story is supposedly the filming of the real James J. Corbett\\'s autobiography \"The Roar of the Crowd\" - but, this movie must be significantly fictionalized.<br /><br />Flynn is a very appealing leading man; he maneuvers the script lightly, and should have been recognized, by the early 1940s, as an excellent actor. Many of Flynn\\'s characterizations were (are?) overlooked as great performances, and this is one of them. Smith does well as his feminine interest, deftly transmitting her emotions for the viewer. Director Walsh makes the silliness look smooth and extravagant. The supporting cast is a treasure trove, from boisterous Alan Hale (as Pat Corbett) to walk-on Lon McCallister (\"Paging Mr. Corbett\").<br /><br />******** Gentleman Jim (1942) Raoul Walsh ~ Errol Flynn, Alexis Smith, Alan Hale', shape=(), dtype=string)\n",
            "targets[0]: tf.Tensor(1, shape=(), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qRaQ6lyOHnvr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Processing words as a set: The bag-of-words approach\n",
        "\n",
        "\n",
        "The simplest way to encode a piece of text for processing by a machine learning\n",
        "model is to discard order and treat it as a set (a “bag”) of tokens. You could either look\n",
        "at individual words (unigrams), or try to recover some local order information by\n",
        "looking at groups of consecutive token (N-grams).\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "6xarF1dHHzb1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### SINGLE WORDS (UNIGRAMS) WITH BINARY ENCODING\n",
        "\n",
        "\n",
        "If you use a bag of single words, the sentence “the cat sat on the mat” becomes :     \n",
        "\n",
        "_{\"cat\", \"mat\", \"on\", \"sat\", \"the\"}_\n",
        "\n",
        "\n",
        "The main advantage of this encoding is that you can represent an entire text as a single vector, where each entry is a presence indicator for a given word.\n",
        "\n",
        " For instance,\n",
        "using binary encoding (multi-hot), you’d encode a text as a vector with as many\n",
        "dimensions as there are words in your vocabulary—with 0s almost everywhere and\n",
        "some 1s for dimensions that encode words present in the text."
      ],
      "metadata": {
        "id": "Fgn2rwRPPQyC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "''' First, let’s process our raw text datasets with a TextVectorization layer so that\n",
        "they yield multi-hot encoded binary word vectors. Our layer will only look at single\n",
        "words (that is to say, unigrams). \n",
        "'''\n",
        "\n"
      ],
      "metadata": {
        "id": "Nfo67hujPQJ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_vectorization = TextVectorization(\n",
        "    max_tokens=20000,\n",
        "    output_mode = \"multi_hot\",\n",
        ")\n",
        "\n",
        "text_only_train_ds = train_ds.map(lambda x, y :x) \n",
        "text_vectorization.adapt(text_only_train_ds)"
      ],
      "metadata": {
        "id": "_d4DFa6JH6Ko",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d8851bf-db71-40ef-d4e8-2d693c7235de"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.9/dist-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
            "Instructions for updating:\n",
            "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "''' Prepare processed\n",
        "versions of our training,\n",
        "validation, and test\n",
        "dataset.\n",
        "Make sure to specify\n",
        "num_parallel_calls to\n",
        "leverage multiple CPU\n",
        "cores.\n",
        " '''\n",
        "\n",
        "binary_1gram_train_ds = train_ds.map(\n",
        "  lambda x, y: (text_vectorization(x), y),\n",
        "  num_parallel_calls=4)\n",
        "\n",
        "binary_1gram_val_ds = val_ds.map(\n",
        "  lambda x, y: (text_vectorization(x), y),\n",
        "  num_parallel_calls=4)\n",
        "\n",
        "binary_1gram_test_ds = test_ds.map(\n",
        "  lambda x, y: (text_vectorization(x), y),\n",
        "  num_parallel_calls=4)"
      ],
      "metadata": {
        "id": "l9qSJIB9d3Bm"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "def get_model(max_tokens=20000, hidden_dim=16):\n",
        "  #tf.keras.backend.clear_session()\n",
        "  inputs = keras.Input(shape=(max_tokens,))\n",
        "  x = layers.Dense(hidden_dim, activation=\"relu\")(inputs)\n",
        "  x = layers.Dropout(0.5)(x)\n",
        "  outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "\n",
        "  model = keras.Model(inputs, outputs)\n",
        "\n",
        "  model.compile(optimizer=\"rmsprop\",\n",
        "      loss=\"binary_crossentropy\",\n",
        "      metrics=[\"accuracy\"])\n",
        "  \n",
        "  return model"
      ],
      "metadata": {
        "id": "33wkAaHleOGu"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = get_model()\n",
        "model.summary()\n",
        "callbacks = [ keras.callbacks.ModelCheckpoint(\"binary_1gram.keras\", save_best_only=True)]\n",
        "\n",
        "#We call cache() on the datasets to cache them in memory , the preprocessing will be did during the first epoch and we will reuse the \n",
        "#preprocessed text for the following epochs \n",
        "\n",
        "\n",
        "model.fit(binary_1gram_train_ds.cache(),\n",
        "          validation_data=binary_1gram_val_ds.cache(),\n",
        "          epochs=10,\n",
        "          callbacks=callbacks)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yyEF3vRceevY",
        "outputId": "efef876a-99e3-4fb8-fda3-41438377af3e"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 20000)]           0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 16)                320016    \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 16)                0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 320,033\n",
            "Trainable params: 320,033\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "625/625 [==============================] - 11s 17ms/step - loss: 0.4031 - accuracy: 0.8294 - val_loss: 0.2986 - val_accuracy: 0.8850\n",
            "Epoch 2/10\n",
            "625/625 [==============================] - 5s 8ms/step - loss: 0.2782 - accuracy: 0.8974 - val_loss: 0.2976 - val_accuracy: 0.8908\n",
            "Epoch 3/10\n",
            "625/625 [==============================] - 6s 9ms/step - loss: 0.2466 - accuracy: 0.9129 - val_loss: 0.3170 - val_accuracy: 0.8828\n",
            "Epoch 4/10\n",
            "625/625 [==============================] - 7s 12ms/step - loss: 0.2308 - accuracy: 0.9189 - val_loss: 0.3396 - val_accuracy: 0.8780\n",
            "Epoch 5/10\n",
            "625/625 [==============================] - 7s 11ms/step - loss: 0.2283 - accuracy: 0.9244 - val_loss: 0.3490 - val_accuracy: 0.8774\n",
            "Epoch 6/10\n",
            "625/625 [==============================] - 8s 12ms/step - loss: 0.2226 - accuracy: 0.9275 - val_loss: 0.3679 - val_accuracy: 0.8782\n",
            "Epoch 7/10\n",
            "625/625 [==============================] - 6s 9ms/step - loss: 0.2197 - accuracy: 0.9286 - val_loss: 0.3808 - val_accuracy: 0.8762\n",
            "Epoch 8/10\n",
            "625/625 [==============================] - 6s 9ms/step - loss: 0.2102 - accuracy: 0.9304 - val_loss: 0.3931 - val_accuracy: 0.8740\n",
            "Epoch 9/10\n",
            "625/625 [==============================] - 5s 8ms/step - loss: 0.2115 - accuracy: 0.9312 - val_loss: 0.4039 - val_accuracy: 0.8760\n",
            "Epoch 10/10\n",
            "625/625 [==============================] - 6s 10ms/step - loss: 0.2149 - accuracy: 0.9323 - val_loss: 0.4104 - val_accuracy: 0.8668\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f443b0bebe0>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.models.load_model(\"binary_1gram.keras\")\n",
        "print(f\"Test acc: {model.evaluate(binary_1gram_test_ds)[1]:.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Y2IsZXVfDTT",
        "outputId": "db316e61-6065-4a7c-a5e2-0a63e19aa88d"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "782/782 [==============================] - 6s 8ms/step - loss: 0.2917 - accuracy: 0.8831\n",
            "Test acc: 0.883\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### BIGRAMS WITH BINARY ENCODING\n",
        "\n",
        "Of course, discarding word order is very reductive, because even atomic concepts can\n",
        "be expressed via multiple words: the term “United States” conveys a concept that is\n",
        "quite distinct from the meaning of the words “states” and “united” taken separately.\n",
        "For this reason, you will usually end up re-injecting local order information into your\n",
        "bag-of-words representation by looking at N-grams rather than single words (most\n",
        "commonly, bigrams).\n",
        "\n",
        "With bigrams, our sentence becomes :\n",
        "```\n",
        "{\"the\", \"the cat\", \"cat\", \"cat sat\", \"sat\",\n",
        "\"sat on\", \"on\", \"on the\", \"the mat\", \"mat\"}\n",
        "```"
      ],
      "metadata": {
        "id": "d0blQtAOgDE9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Configuring the TextVectorization layer to return bigrams\n",
        "\n",
        "text_vectorization =  TextVectorization(\n",
        "    ngrams = 2,\n",
        "    max_tokens = 20000,\n",
        "    output_mode = \"multi_hot\"\n",
        ")"
      ],
      "metadata": {
        "id": "VxFK2q3egW7U"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training and testing the binary bigram model\n",
        "\n",
        "text_vectorization.adapt(text_only_train_ds)\n",
        "\n",
        "binary_2gram_train_ds = train_ds.map(\n",
        "  lambda x, y: (text_vectorization(x), y),\n",
        "  num_parallel_calls=4)\n",
        "\n",
        "binary_2gram_val_ds = val_ds.map(\n",
        "  lambda x, y: (text_vectorization(x), y),\n",
        "  num_parallel_calls=4)\n",
        "\n",
        "binary_2gram_test_ds = test_ds.map(\n",
        "  lambda x, y: (text_vectorization(x), y),\n",
        "  num_parallel_calls=4)"
      ],
      "metadata": {
        "id": "_-OqBPs2gqDZ"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = get_model()\n",
        "model.summary()\n",
        "\n",
        "callbacks = [\n",
        "keras.callbacks.ModelCheckpoint(\"binary_2gram.keras\",\n",
        "      save_best_only=True)\n",
        "                ]\n",
        "\n",
        "\n",
        "model.fit(binary_2gram_train_ds.cache(),\n",
        "    validation_data=binary_2gram_val_ds.cache(),\n",
        "    epochs=10,\n",
        "        callbacks=callbacks)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8CqaDs8fg9cg",
        "outputId": "43c74759-47d8-4724-c8a9-0e98d8e320b0"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 20000)]           0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 16)                320016    \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 16)                0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 320,033\n",
            "Trainable params: 320,033\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "625/625 [==============================] - 11s 17ms/step - loss: 0.3701 - accuracy: 0.8443 - val_loss: 0.2705 - val_accuracy: 0.9000\n",
            "Epoch 2/10\n",
            "625/625 [==============================] - 5s 8ms/step - loss: 0.2352 - accuracy: 0.9155 - val_loss: 0.2819 - val_accuracy: 0.9018\n",
            "Epoch 3/10\n",
            "625/625 [==============================] - 6s 9ms/step - loss: 0.1998 - accuracy: 0.9336 - val_loss: 0.2971 - val_accuracy: 0.8984\n",
            "Epoch 4/10\n",
            "625/625 [==============================] - 5s 8ms/step - loss: 0.1864 - accuracy: 0.9417 - val_loss: 0.3133 - val_accuracy: 0.9004\n",
            "Epoch 5/10\n",
            "625/625 [==============================] - 6s 9ms/step - loss: 0.1658 - accuracy: 0.9513 - val_loss: 0.3317 - val_accuracy: 0.8944\n",
            "Epoch 6/10\n",
            "625/625 [==============================] - 5s 8ms/step - loss: 0.1638 - accuracy: 0.9531 - val_loss: 0.3454 - val_accuracy: 0.8918\n",
            "Epoch 7/10\n",
            "625/625 [==============================] - 6s 9ms/step - loss: 0.1567 - accuracy: 0.9559 - val_loss: 0.3711 - val_accuracy: 0.8904\n",
            "Epoch 8/10\n",
            "625/625 [==============================] - 5s 8ms/step - loss: 0.1539 - accuracy: 0.9578 - val_loss: 0.3781 - val_accuracy: 0.8946\n",
            "Epoch 9/10\n",
            "625/625 [==============================] - 5s 7ms/step - loss: 0.1599 - accuracy: 0.9571 - val_loss: 0.3939 - val_accuracy: 0.8890\n",
            "Epoch 10/10\n",
            "625/625 [==============================] - 6s 9ms/step - loss: 0.1506 - accuracy: 0.9578 - val_loss: 0.4009 - val_accuracy: 0.8900\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f4428bef0d0>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.models.load_model(\"binary_2gram.keras\")\n",
        "print(f\"Test acc: {model.evaluate(binary_2gram_test_ds)[1]:.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fOvhn0_MiUYC",
        "outputId": "eb547fa9-5c6e-4cfb-a9ff-92803e053d05"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "782/782 [==============================] - 7s 9ms/step - loss: 0.2667 - accuracy: 0.8999\n",
            "Test acc: 0.900\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Wl-S-haQiVAy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### BIGRAMS WITH TF-IDF ENCODING\n",
        "\n",
        "You can also add a bit more information to this representation by counting how many\n",
        "times each word or N-gram occurs, that is to say, by taking the histogram of the words\n",
        "over the text:\n",
        "\n",
        "```\n",
        "{\"the\": 2, \"the cat\": 1, \"cat\": 1, \"cat sat\": 1, \"sat\": 1,\n",
        "\"sat on\": 1, \"on\": 1, \"on the\": 1, \"the mat: 1\", \"mat\": 1}\n",
        "```"
      ],
      "metadata": {
        "id": "5-GJG6xFiauK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Configuring the TextVectorization layer to return token counts\n",
        "\n",
        "text_vectorization = TextVectorization(\n",
        "  ngrams=2,\n",
        "  max_tokens=20000,\n",
        "  output_mode=\"count\"\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "id": "55M5YYA8ibtS"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "some common words (like \"the,\" \"a,\" \"is,\" and \"are\") dominating word counts in NLP tasks. These words are not very useful for classification purposes, but they show up frequently in texts, which can make it difficult to identify the most informative words for classification.\n",
        "\n",
        "To address this issue, we can apply a normalization scheme called TF-IDF, which stands for \"term frequency, inverse document frequency.\" This normalization scheme considers the frequency of a term in a document and how often it appears in other documents. By dividing the term frequency by the inverse document frequency, TF-IDF gives more weight to words that appear frequently in one document but not in many others, and less weight to words that appear frequently across all documents. This helps to identify the most informative words for classification purposes, regardless of how common or rare they are in the text."
      ],
      "metadata": {
        "id": "iZouhwBJkADu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Understanding TF-IDF normalization\n",
        "\n",
        "''' The more a given term appears in a document, the more important that term is for\n",
        "understanding what the document is about. At the same time, the frequency at which\n",
        "the term appears across all documents in your dataset matters too: terms that\n",
        "appear in almost every document (like “the” or “a”) aren’t particularly informative,\n",
        "while terms that appear only in a small subset of all texts (like “Herzog”) are very dis-\n",
        "tinctive, and thus important. TF-IDF is a metric that fuses these two ideas. It weights\n",
        "a given term by taking “term frequency,” how many times the term appears in the\n",
        "current document, and dividing it by a measure of “document frequency,” which esti-\n",
        "mates how often the term comes up across the dataset. You’d compute it as follows: '''\n",
        "\n",
        "def tfidf(term, document, dataset):\n",
        "  term_freq = document.count(term)\n",
        "  doc_freq = math.log(sum(doc.count(term) for doc in dataset) + 1)\n",
        "  return term_freq / doc_freq"
      ],
      "metadata": {
        "id": "8bm8qo0Zi09E"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Configuring TextVectorization to return TF-IDF-weighted outputs\n",
        "\n",
        "text_vectorization = TextVectorization(\n",
        "    ngrams=2,\n",
        "    max_tokens=20000,\n",
        "    output_mode=\"tf_idf\",\n",
        ")"
      ],
      "metadata": {
        "id": "n9nposKNkzga"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training and testing the TF-IDF bigram model\n",
        "\n",
        "text_vectorization.adapt(text_only_train_ds)\n",
        "\n",
        "tfidf_2gram_train_ds = train_ds.map(\n",
        "    lambda x, y: (text_vectorization(x), y),\n",
        "    num_parallel_calls=4)\n",
        "\n",
        "\n",
        "tfidf_2gram_val_ds = val_ds.map(\n",
        "    lambda x, y: (text_vectorization(x), y),\n",
        "    num_parallel_calls=4)\n",
        "\n",
        "\n",
        "tfidf_2gram_test_ds = test_ds.map(\n",
        "    lambda x, y: (text_vectorization(x), y),\n",
        "    num_parallel_calls=4)"
      ],
      "metadata": {
        "id": "8RP8D61Ek67N"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = get_model()\n",
        "model.summary()\n",
        "\n",
        "callbacks = [\n",
        "    keras.callbacks.ModelCheckpoint(\"tfidf_2gram.keras\",\n",
        "    save_best_only=True)\n",
        "    ]\n",
        "\n",
        "\n",
        "model.fit(tfidf_2gram_train_ds.cache(),\n",
        "      validation_data=tfidf_2gram_val_ds.cache(),\n",
        "      epochs=10,\n",
        "        callbacks=callbacks)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gls2dloglO3z",
        "outputId": "de67cbe8-12a2-456c-e924-adcb0f2409c6"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_3 (InputLayer)        [(None, 20000)]           0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 16)                320016    \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 16)                0         \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 320,033\n",
            "Trainable params: 320,033\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "625/625 [==============================] - 12s 17ms/step - loss: 0.5380 - accuracy: 0.7699 - val_loss: 0.3235 - val_accuracy: 0.8812\n",
            "Epoch 2/10\n",
            "625/625 [==============================] - 5s 8ms/step - loss: 0.3450 - accuracy: 0.8457 - val_loss: 0.3035 - val_accuracy: 0.8838\n",
            "Epoch 3/10\n",
            "625/625 [==============================] - 5s 8ms/step - loss: 0.3108 - accuracy: 0.8638 - val_loss: 0.3688 - val_accuracy: 0.8788\n",
            "Epoch 4/10\n",
            "625/625 [==============================] - 5s 8ms/step - loss: 0.2824 - accuracy: 0.8751 - val_loss: 0.3222 - val_accuracy: 0.8818\n",
            "Epoch 5/10\n",
            "625/625 [==============================] - 5s 8ms/step - loss: 0.2736 - accuracy: 0.8818 - val_loss: 0.3261 - val_accuracy: 0.8782\n",
            "Epoch 6/10\n",
            "625/625 [==============================] - 6s 10ms/step - loss: 0.2583 - accuracy: 0.8855 - val_loss: 0.3699 - val_accuracy: 0.8766\n",
            "Epoch 7/10\n",
            "625/625 [==============================] - 5s 9ms/step - loss: 0.2519 - accuracy: 0.8843 - val_loss: 0.3522 - val_accuracy: 0.8914\n",
            "Epoch 8/10\n",
            "625/625 [==============================] - 5s 9ms/step - loss: 0.2448 - accuracy: 0.8929 - val_loss: 0.3547 - val_accuracy: 0.8824\n",
            "Epoch 9/10\n",
            "625/625 [==============================] - 5s 7ms/step - loss: 0.2341 - accuracy: 0.8968 - val_loss: 0.3447 - val_accuracy: 0.8768\n",
            "Epoch 10/10\n",
            "625/625 [==============================] - 6s 9ms/step - loss: 0.2241 - accuracy: 0.9053 - val_loss: 0.3741 - val_accuracy: 0.8626\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f443bf5d3a0>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.models.load_model(\"tfidf_2gram.keras\")\n",
        "print(f\"Test acc: {model.evaluate(tfidf_2gram_test_ds)[1]:.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8vZmld5UlzV6",
        "outputId": "77af29bc-a60d-472c-9c05-ff52f3132bc0"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "782/782 [==============================] - 7s 9ms/step - loss: 0.3095 - accuracy: 0.8817\n",
            "Test acc: 0.882\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Exporting a model that processes raw strings\n",
        "\n",
        "In the preceding examples, we did our text standardization, splitting, and indexing as\n",
        "part of the tf.data pipeline. But if we want to export a standalone model indepen-\n",
        "dent of this pipeline, we should make sure that it incorporates its own text prepro-\n",
        "cessing (otherwise, you’d have to reimplement in the production environment, which\n",
        "can be challenging or can lead to subtle discrepancies between the training data and\n",
        "the production data). Thankfully, this is easy."
      ],
      "metadata": {
        "id": "fuvzHAtpmUpx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Just create a new model that reuses your TextVectorization layer and adds to it\n",
        "#the model you just trained:\n",
        "\n",
        "inputs = keras.Input(shape=(1,), dtype=\"string\")\n",
        "# apply text preprocessing\n",
        "processed_inputs = text_vectorization(inputs)\n",
        "# apply the previously trained model\n",
        "outputs = model(processed_inputs)\n",
        "#instantiate a end-to-end model\n",
        "inference_model = keras.Model(inputs, outputs)"
      ],
      "metadata": {
        "id": "_yyx4s-6mtdQ"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The resulting model can process batches of raw strings:\n",
        "import tensorflow as tf\n",
        "raw_text_data = tf.convert_to_tensor([\n",
        "    [\"That was an excellent movie, I loved it.\"],\n",
        "])\n",
        "\n",
        "predictions = inference_model(raw_text_data)\n",
        "print(f\"{float(predictions[0] * 100):.2f} percent positive\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V_yozvYOniRC",
        "outputId": "19738066-6e99-4939-902a-d81247cc1714"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "95.63 percent positive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "F7laYKfhn1_T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Processing words as a sequence: The sequence model approach\n",
        "the\n",
        "history of deep learning is that of a move away from manual feature engineering, toward\n",
        "letting models learn their own features from exposure to data alone. What if, instead of\n",
        "manually crafting order-based features, we exposed the model to raw word sequences\n",
        "and let it figure out such features on its own? This is what sequence models are about.\n",
        "\n",
        "\n",
        "\n",
        "To implement a sequence model, you’d start by representing your input samples as\n",
        "sequences of integer indices (one integer standing for one word). Then, you’d map\n",
        "each integer to a vector to obtain vector sequences. Finally, you’d feed these\n",
        "sequences of vectors into a stack of layers that could cross-correlate features from adja-\n",
        "cent vectors, such as a 1D convnet, a RNN, or a Transformer."
      ],
      "metadata": {
        "id": "NUSouREKn8mV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### A FIRST PRACTICAL EXAMPLE\n",
        "\n",
        "Let’s try out a first sequence model in practice. First, let’s prepare datasets that return\n",
        "integer sequences."
      ],
      "metadata": {
        "id": "f6CsZS5AqpFm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Preparing integer sequence dataset\n",
        "import tensorflow as tf \n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers \n",
        "\n",
        "max_length = 600\n",
        "max_tokens = 20000\n",
        "\n",
        "text_vectorization = layers.TextVectorization(\n",
        "    max_tokens=max_tokens,\n",
        "    output_mode=\"int\",\n",
        "    output_sequence_length=max_length,\n",
        ")"
      ],
      "metadata": {
        "id": "B40GYBQnogDT"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_vectorization.adapt(text_only_train_ds)\n",
        "\n",
        "\n",
        "int_train_ds = train_ds.map(\n",
        "lambda x, y: (text_vectorization(x), y),\n",
        "num_parallel_calls=4)\n",
        "\n",
        "int_val_ds = val_ds.map(\n",
        "lambda x, y: (text_vectorization(x), y),\n",
        "num_parallel_calls=4)\n",
        "\n",
        "int_test_ds = test_ds.map(\n",
        "lambda x, y: (text_vectorization(x), y),\n",
        "num_parallel_calls=4)"
      ],
      "metadata": {
        "id": "vAufGolLrCm3"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "''' Next, let’s make a model. The simplest way to convert our integer sequences to vector\n",
        "sequences is to one-hot encode the integers (each dimension would represent one\n",
        "possible term in the vocabulary). On top of these one-hot vectors, we’ll add a simple\n",
        "bidirectional LSTM. '''\n",
        "\n",
        "# A sequence model built on one-hot encoded vector sequences\n",
        "\n",
        "inputs = keras.Input(shape=(None,), dtype=\"int64\")\n",
        "embedded = tf.one_hot(inputs, depth=max_tokens)\n",
        "x = layers.Bidirectional(layers.LSTM(32))(embedded)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "\n",
        "model = keras.Model(inputs, outputs)\n",
        "\n",
        "model.compile(optimizer=\"rmsprop\",\n",
        "    loss=\"binary_crossentropy\",\n",
        "    metrics=[\"accuracy\"])\n",
        "\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8f5xbz59reHn",
        "outputId": "ed9948ae-0b03-49ab-8cb3-e2414469e943"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, None)]            0         \n",
            "                                                                 \n",
            " tf.one_hot (TFOpLambda)     (None, None, 20000)       0         \n",
            "                                                                 \n",
            " bidirectional (Bidirectiona  (None, 64)               5128448   \n",
            " l)                                                              \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 64)                0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,128,513\n",
            "Trainable params: 5,128,513\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Training a first basic sequence model\n",
        "\n",
        "callbacks = [\n",
        "keras.callbacks.ModelCheckpoint(\"one_hot_bidir_lstm.keras\",\n",
        "save_best_only=True)]\n",
        "\n",
        "model.fit(int_train_ds, validation_data=int_val_ds, epochs=10,callbacks=callbacks)"
      ],
      "metadata": {
        "id": "xKdX-0_0r8c6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This dataset is very heavy , its a matrix of shape(600,20000), the training will be very slow and RAM expensive , and the accuracy will be around only 87%, on low GPU-RAM machine , it's clearly don't worth it , another approach , more accurate and less expensive is **word embedding**"
      ],
      "metadata": {
        "id": "tlTQq19lx0TN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### UNDERSTANDING WORD EMBEDDINGS\n",
        "\n",
        "Word embeddings are vector representations of words that achieve exactly this: they\n",
        "map human language into a structured geometric space.\n",
        "\n",
        "Besides being dense representations, word embeddings are also structured representa-\n",
        "tions, and their structure is learned from data. Similar words get embedded in close\n",
        "locations, and further, specific directions in the embedding space are meaningful. To\n",
        "make this clearer, let’s look at a concrete example.\n",
        "\n",
        "\n",
        "In figure 11.3, four words are embedded on a 2D plane: cat, dog, wolf, and tiger.\n",
        "With the vector representations we chose here, some semantic relationships between\n",
        "these words can be encoded as geometric transformations. For instance, the same\n",
        "vector allows us to go from cat to tiger and from dog to wolf: this vector could be inter-\n",
        "preted as the “from pet to wild animal” vector. Similarly, another vector lets us go\n",
        "from dog to cat and from wolf to tiger, which could be interpreted as a “from canine\n",
        "to feline” vector.\n",
        "\n",
        "![image.png](data:image/png;base64,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)\n",
        "\n",
        "\n",
        "There are two ways\n",
        "to obtain word embeddings: \n",
        "\n",
        " - Learn word embeddings jointly with the main task you care about (such as doc-\n",
        "ument classification or sentiment prediction). In this setup, you start with ran-\n",
        "dom word vectors and then learn word vectors in the same way you learn the\n",
        "weights of a neural network.\n",
        "\n",
        " - Load into your model word embeddings that were precomputed using a differ-\n",
        "ent machine learning task than the one you’re trying to solve. These are called\n",
        "pretrained word embeddings."
      ],
      "metadata": {
        "id": "FaiAAt28yhru"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "d6ndu2Iwybqw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### LEARNING WORD EMBEDDINGS WITH THE EMBEDDING LAYER\n",
        "\n",
        "Thre's not a word-embdedding space that would perfectly map human language, ther are many different languages and they are not isophonic to one another.\n",
        "\n",
        "\n",
        "But\n",
        "more pragmatically, what makes a good word-embedding space depends heavily on\n",
        "your task: the perfect word-embedding space for an English-language movie-review\n",
        "sentiment-analysis model may look different from the perfect embedding space for an\n",
        "English-language legal-document classification model, because the importance of cer-\n",
        "tain semantic relationships varies from task to task."
      ],
      "metadata": {
        "id": "m96LNrsP0Qgy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiating an Embedding layer\n",
        "\n",
        "embedding_layer = layers.Embedding(input_dim=max_tokens, output_dim=256)\n",
        "\n",
        "#The Embedding layer takes at least two arguments: the number of\n",
        "#possible tokens and the dimensionality of the embeddings (here, 256)."
      ],
      "metadata": {
        "id": "k3hma1s_0RsP"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0a681U0u1yaS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Embedding layer is best understood as a dictionary that maps integer indices\n",
        "(which stand for specific words) to dense vectors. It takes integers as input, looks up\n",
        "these integers in an internal dictionary, and returns the associated vectors. It’s effectively a dictionary lookup .\n",
        "\n",
        "\n",
        "\n",
        "The Embedding layer takes as input a rank-2 tensor of integers, of shape (batch_size,\n",
        "sequence_length), where each entry is a sequence of integers. The layer then returns\n",
        "a 3D floating-point tensor of shape (batch_size, sequence_length, embedding_\n",
        "dimensionality)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "OUs__7NH15Q4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Model that uses an Embedding layer trained from scratch\n",
        "\n",
        "inputs = keras.Input(shape=(None,), dtype=\"int64\")\n",
        "\n",
        "embedded = layers.Embedding(input_dim=max_tokens, output_dim=256)(inputs)\n",
        "x = layers.Bidirectional(layers.LSTM(32))(embedded)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "\n",
        "model = keras.Model(inputs, outputs)\n",
        "\n",
        "model.compile(optimizer=\"rmsprop\",loss=\"binary_crossentropy\",metrics=[\"accuracy\"])\n",
        "\n",
        "callbacks = [\n",
        "keras.callbacks.ModelCheckpoint(\"embeddings_bidir_gru.keras\",\n",
        "save_best_only=True)\n",
        "]\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pkc1ZJej17zR",
        "outputId": "68044348-c835-4084-a12b-7356368e2790"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_3 (InputLayer)        [(None, None)]            0         \n",
            "                                                                 \n",
            " embedding_2 (Embedding)     (None, None, 256)         5120000   \n",
            "                                                                 \n",
            " bidirectional_2 (Bidirectio  (None, 64)               73984     \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,194,049\n",
            "Trainable params: 5,194,049\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(int_train_ds, validation_data=int_val_ds, epochs=10,callbacks=callbacks)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lhuLLi_t2c2S",
        "outputId": "bef4c6b6-f452-4301-c382-024686b65d22"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "625/625 [==============================] - 61s 92ms/step - loss: 0.5325 - accuracy: 0.7254 - val_loss: 0.4275 - val_accuracy: 0.8304\n",
            "Epoch 2/10\n",
            "625/625 [==============================] - 38s 61ms/step - loss: 0.3450 - accuracy: 0.8684 - val_loss: 0.3346 - val_accuracy: 0.8668\n",
            "Epoch 3/10\n",
            "625/625 [==============================] - 32s 51ms/step - loss: 0.2735 - accuracy: 0.9015 - val_loss: 0.3445 - val_accuracy: 0.8692\n",
            "Epoch 4/10\n",
            "625/625 [==============================] - 28s 44ms/step - loss: 0.2355 - accuracy: 0.9185 - val_loss: 0.3566 - val_accuracy: 0.8710\n",
            "Epoch 5/10\n",
            "625/625 [==============================] - 28s 44ms/step - loss: 0.1956 - accuracy: 0.9337 - val_loss: 0.4083 - val_accuracy: 0.8682\n",
            "Epoch 6/10\n",
            "625/625 [==============================] - 26s 42ms/step - loss: 0.1724 - accuracy: 0.9431 - val_loss: 0.3898 - val_accuracy: 0.8766\n",
            "Epoch 7/10\n",
            "625/625 [==============================] - 27s 42ms/step - loss: 0.1498 - accuracy: 0.9525 - val_loss: 0.3998 - val_accuracy: 0.8578\n",
            "Epoch 8/10\n",
            "625/625 [==============================] - 25s 39ms/step - loss: 0.1301 - accuracy: 0.9594 - val_loss: 0.4364 - val_accuracy: 0.8710\n",
            "Epoch 9/10\n",
            "625/625 [==============================] - 26s 41ms/step - loss: 0.1130 - accuracy: 0.9656 - val_loss: 0.5520 - val_accuracy: 0.8332\n",
            "Epoch 10/10\n",
            "625/625 [==============================] - 25s 41ms/step - loss: 0.0920 - accuracy: 0.9724 - val_loss: 0.4713 - val_accuracy: 0.8658\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f2870c196a0>"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.models.load_model(\"embeddings_bidir_gru.keras\")\n",
        "print(f\"Test acc: {model.evaluate(int_test_ds)[1]:.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mndlluo45bkU",
        "outputId": "14cc7906-335d-4c2d-bf08-ab66efa2c1d2"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "782/782 [==============================] - 14s 16ms/step - loss: 0.3459 - accuracy: 0.8560\n",
            "Test acc: 0.856\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### UNDERSTANDING PADDING AND MASKING\n",
        "\n",
        "\n",
        "One thing that’s slightly hurting model performance here is that our input sequences\n",
        "are full of zeros. This comes from our use of the output_sequence_length=max_\n",
        "length option in TextVectorization (with max_length equal to 600): sentences lon-\n",
        "ger than 600 tokens are truncated to a length of 600 tokens, and sentences shorter\n",
        "than 600 tokens are padded with zeros at the end so that they can be concatenated\n",
        "together with other sequences to form contiguous batches."
      ],
      "metadata": {
        "id": "bgauQp1b7wW3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We’re using a bidirectional RNN: two RNN layers running in parallel, with one\n",
        "processing the tokens in their natural order, and the other processing the same\n",
        "tokens in reverse. The RNN that looks at the tokens in their natural order will spend\n",
        "its last iterations seeing only vectors that encode padding—possibly for several hun-\n",
        "dreds of iterations if the original sentence was short. The information stored in the\n",
        "internal state of the RNN will gradually fade out as it gets exposed to these meaning-\n",
        "less inputs.\n",
        "We need some way to tell the RNN that it should skip these iterations. There’s an\n",
        "API for that: masking.\n",
        "The Embedding layer is capable of generating a “mask” that corresponds to its\n",
        "input data. This mask is a tensor of ones and zeros (or True/False booleans), of shape\n",
        "(batch_size, sequence_length), where the entry mask[i, t] indicates where time-\n",
        "step t of sample i should be skipped or not (the timestep will be skipped if mask[i, t]\n",
        "is 0 or False, and processed otherwise)."
      ],
      "metadata": {
        "id": "Sp0z_zoe8b4A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import Embedding\n",
        "embedding_layer = Embedding(input_dim=10, output_dim=256, mask_zero=True)"
      ],
      "metadata": {
        "id": "kmzAdqNy7uW7"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "some_input = [\n",
        "[4, 3, 2, 1, 0, 0, 0],\n",
        "[5, 4, 3, 2, 1, 0, 0],\n",
        "[2, 1, 0, 0, 0, 0, 0]]\n",
        "\n",
        "mask = embedding_layer.compute_mask(some_input)"
      ],
      "metadata": {
        "id": "Zc3Jp4XC8zLA"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mask"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NMmAnU145cET",
        "outputId": "59de44aa-31a2-4837-a6c5-404f9ad9abec"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3, 7), dtype=bool, numpy=\n",
              "array([[ True,  True,  True,  True, False, False, False],\n",
              "       [ True,  True,  True,  True,  True, False, False],\n",
              "       [ True,  True, False, False, False, False, False]])>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Using an Embedding layer with masking enabled\n",
        "\n",
        "inputs = keras.Input(shape=(None,), dtype=\"int64\")\n",
        "embedded = layers.Embedding(\n",
        "input_dim=max_tokens, output_dim=256, mask_zero=True)(inputs)\n",
        "x = layers.Bidirectional(layers.LSTM(32))(embedded)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "\n",
        "model = keras.Model(inputs, outputs)\n",
        "\n",
        "model.compile(optimizer=\"rmsprop\",loss=\"binary_crossentropy\",metrics=[\"accuracy\"])\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l1MNpxQp88xt",
        "outputId": "ec02617e-3d37-4b19-8ead-123864b433fe"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_4 (InputLayer)        [(None, None)]            0         \n",
            "                                                                 \n",
            " embedding_4 (Embedding)     (None, None, 256)         5120000   \n",
            "                                                                 \n",
            " bidirectional_3 (Bidirectio  (None, 64)               73984     \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,194,049\n",
            "Trainable params: 5,194,049\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "callbacks = [keras.callbacks.ModelCheckpoint(\"embeddings_bidir_gru_with_masking.keras\",save_best_only=True)]\n",
        "\n",
        "model.fit(int_train_ds, validation_data=int_val_ds, epochs=10,callbacks=callbacks)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "opqMmAuV9Tnq",
        "outputId": "c5161b78-4989-4a84-ce67-422272348a9b"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "625/625 [==============================] - 78s 113ms/step - loss: 0.4370 - accuracy: 0.7865 - val_loss: 0.3578 - val_accuracy: 0.8572\n",
            "Epoch 2/10\n",
            "625/625 [==============================] - 43s 69ms/step - loss: 0.2753 - accuracy: 0.8919 - val_loss: 0.3259 - val_accuracy: 0.8670\n",
            "Epoch 3/10\n",
            "625/625 [==============================] - 36s 58ms/step - loss: 0.2042 - accuracy: 0.9230 - val_loss: 0.3149 - val_accuracy: 0.8814\n",
            "Epoch 4/10\n",
            "625/625 [==============================] - 33s 53ms/step - loss: 0.1601 - accuracy: 0.9448 - val_loss: 0.3748 - val_accuracy: 0.8618\n",
            "Epoch 5/10\n",
            "625/625 [==============================] - 32s 51ms/step - loss: 0.1228 - accuracy: 0.9582 - val_loss: 0.3870 - val_accuracy: 0.8762\n",
            "Epoch 6/10\n",
            "625/625 [==============================] - 33s 53ms/step - loss: 0.0978 - accuracy: 0.9663 - val_loss: 0.3822 - val_accuracy: 0.8750\n",
            "Epoch 7/10\n",
            "625/625 [==============================] - 30s 48ms/step - loss: 0.0765 - accuracy: 0.9753 - val_loss: 0.4579 - val_accuracy: 0.8690\n",
            "Epoch 8/10\n",
            "625/625 [==============================] - 31s 49ms/step - loss: 0.0580 - accuracy: 0.9808 - val_loss: 0.4754 - val_accuracy: 0.8788\n",
            "Epoch 9/10\n",
            "625/625 [==============================] - 29s 47ms/step - loss: 0.0446 - accuracy: 0.9848 - val_loss: 0.4837 - val_accuracy: 0.8824\n",
            "Epoch 10/10\n",
            "625/625 [==============================] - 29s 46ms/step - loss: 0.0343 - accuracy: 0.9893 - val_loss: 0.5401 - val_accuracy: 0.8754\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f2871b398b0>"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.models.load_model(\"embeddings_bidir_gru_with_masking.keras\")\n",
        "print(f\"Test acc: {model.evaluate(int_test_ds)[1]:.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LYmKjclL_ksG",
        "outputId": "89199b88-905e-4d28-bbec-4bec363dd1a2"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "782/782 [==============================] - 17s 18ms/step - loss: 0.3200 - accuracy: 0.8745\n",
            "Test acc: 0.874\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### USING PRETRAINED WORD EMBEDDINGS\n",
        "\n",
        "\n",
        "Sometimes you have so little training data available that you can’t use your data alone\n",
        "to learn an appropriate task-specific embedding of your vocabulary. In such cases,\n",
        "instead of learning word embeddings jointly with the problem you want to solve, you\n",
        "can load embedding vectors from a precomputed embedding space that you know is\n",
        "highly structured and exhibits useful properties—one that captures generic aspects of\n",
        "language structure. The rationale behind using pretrained word embeddings in natu-\n",
        "ral language processing is much the same as for using pretrained convnets in image\n",
        "classification: you don’t have enough data available to learn truly powerful features on\n",
        "your own, but you expect that the features you need are fairly generic—that is, com-\n",
        "mon visual features or semantic features. In this case, it makes sense to reuse features\n",
        "learned on a different problem.\n",
        "\n",
        "\n",
        "\n",
        "There are various precomputed databases of word embeddings that you can down-\n",
        "load and use in a Keras Embedding layer. Word2vec is one of them. Another popular\n",
        "one is called Global Vectors for Word Representation [Glove](https://nlp.stanford.edu/projects/glove), which was developed by Stanford researchers in 2014. This\n",
        "embedding technique is based on factorizing a matrix of word co-occurrence statis-\n",
        "tics. Its developers have made available precomputed embeddings for millions of\n",
        "English tokens, obtained from Wikipedia data and Common Crawl data.\n",
        "Let’s look at how you can get started using GloVe embeddings in a Keras model.\n",
        "The same method is valid for Word2Vec embeddings or any other word-embedding\n",
        "database."
      ],
      "metadata": {
        "id": "kRO7Gqyp_uzD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "''' First, let’s download the GloVe word embeddings precomputed on the 2014\n",
        "English Wikipedia dataset. It’s an 822 MB zip file containing 100-dimensional embed-\n",
        "ding vectors for 400,000 words (or non-word tokens). '''\n",
        "\n",
        "\n",
        "!wget http://nlp.stanford.edu/data/glove.6B.zip\n",
        "!unzip -q glove.6B.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sWtx7Ogg_lnU",
        "outputId": "2254bec8-757e-4616-a849-af2884c39e9d"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-03-16 10:41:12--  http://nlp.stanford.edu/data/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
            "--2023-03-16 10:41:12--  https://nlp.stanford.edu/data/glove.6B.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
            "--2023-03-16 10:41:13--  https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: ‘glove.6B.zip’\n",
            "\n",
            "glove.6B.zip        100%[===================>] 822.24M  5.02MB/s    in 2m 39s  \n",
            "\n",
            "2023-03-16 10:43:52 (5.17 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "path_to_glove_file = \"glove.6B.100d.txt\"\n",
        "\n",
        "embeddings_index = {}\n",
        "\n",
        "with open(path_to_glove_file) as f:\n",
        "  for line in f:\n",
        "    word, coefs = line.split(maxsplit=1)\n",
        "    coefs = np.fromstring(coefs, \"f\", sep=\" \")\n",
        "    embeddings_index[word] = coefs\n",
        "\n",
        "print(f\"Found {len(embeddings_index)} word vectors.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sHz9uYEMBYHp",
        "outputId": "6d9f6e95-44d9-409d-f0ab-18260040caac"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 400000 word vectors.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Preparing the GloVe word-embeddings matrix\n",
        "\n",
        "embedding_dim = 100\n",
        "\n",
        "vocabulary = text_vectorization.get_vocabulary()\n",
        "word_index = dict(zip(vocabulary, range(len(vocabulary))))\n",
        "\n",
        "\n",
        "embedding_matrix = np.zeros((max_tokens, embedding_dim))\n",
        "for word, i in word_index.items():\n",
        "  if i < max_tokens:\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "  if embedding_vector is not None:\n",
        "    embedding_matrix[i] = embedding_vector\n",
        "    "
      ],
      "metadata": {
        "id": "3Zx05m2uBmRR"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_layer = layers.Embedding(\n",
        "  max_tokens,\n",
        "  embedding_dim,\n",
        "  embeddings_initializer=keras.initializers.Constant(embedding_matrix),\n",
        "  trainable=False,\n",
        "  mask_zero=True,\n",
        "  )"
      ],
      "metadata": {
        "id": "9_QySWTjCHLt"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model that uses a pretrained Embedding layer\n",
        "\n",
        "inputs = keras.Input(shape=(None,), dtype=\"int64\")\n",
        "embedded = embedding_layer(inputs)\n",
        "x = layers.Bidirectional(layers.LSTM(32))(embedded)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "\n",
        "model = keras.Model(inputs, outputs)\n",
        "\n",
        "model.compile(optimizer=\"rmsprop\",loss=\"binary_crossentropy\",metrics=[\"accuracy\"])\n",
        "\n",
        "model.summary()\n",
        "\n",
        "callbacks = [keras.callbacks.ModelCheckpoint(\"glove_embeddings_sequence_model.keras\",save_best_only=True)]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gyWOeOAPCXfT",
        "outputId": "5bae651f-0c36-4d24-c6bd-d659fc1f17d0"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_5 (InputLayer)        [(None, None)]            0         \n",
            "                                                                 \n",
            " embedding_5 (Embedding)     (None, None, 100)         2000000   \n",
            "                                                                 \n",
            " bidirectional_4 (Bidirectio  (None, 64)               34048     \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,034,113\n",
            "Trainable params: 34,113\n",
            "Non-trainable params: 2,000,000\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(int_train_ds, validation_data=int_val_ds, epochs=10,callbacks=callbacks)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1wQa8iLXCqnE",
        "outputId": "108affc7-7480-4943-f829-a3d7108ef4fe"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "625/625 [==============================] - 42s 54ms/step - loss: 0.5793 - accuracy: 0.6900 - val_loss: 0.4760 - val_accuracy: 0.7830\n",
            "Epoch 2/10\n",
            "625/625 [==============================] - 30s 48ms/step - loss: 0.4548 - accuracy: 0.7939 - val_loss: 0.4537 - val_accuracy: 0.7898\n",
            "Epoch 3/10\n",
            "625/625 [==============================] - 29s 47ms/step - loss: 0.4014 - accuracy: 0.8207 - val_loss: 0.3832 - val_accuracy: 0.8312\n",
            "Epoch 4/10\n",
            "625/625 [==============================] - 28s 45ms/step - loss: 0.3704 - accuracy: 0.8382 - val_loss: 0.3687 - val_accuracy: 0.8436\n",
            "Epoch 5/10\n",
            "625/625 [==============================] - 27s 43ms/step - loss: 0.3469 - accuracy: 0.8528 - val_loss: 0.3743 - val_accuracy: 0.8444\n",
            "Epoch 6/10\n",
            "625/625 [==============================] - 32s 51ms/step - loss: 0.3248 - accuracy: 0.8622 - val_loss: 0.3568 - val_accuracy: 0.8528\n",
            "Epoch 7/10\n",
            "625/625 [==============================] - 30s 47ms/step - loss: 0.3071 - accuracy: 0.8703 - val_loss: 0.3319 - val_accuracy: 0.8638\n",
            "Epoch 8/10\n",
            "625/625 [==============================] - 29s 46ms/step - loss: 0.2884 - accuracy: 0.8809 - val_loss: 0.3274 - val_accuracy: 0.8664\n",
            "Epoch 9/10\n",
            "625/625 [==============================] - 28s 45ms/step - loss: 0.2755 - accuracy: 0.8892 - val_loss: 0.3304 - val_accuracy: 0.8664\n",
            "Epoch 10/10\n",
            "625/625 [==============================] - 27s 43ms/step - loss: 0.2596 - accuracy: 0.8949 - val_loss: 0.3553 - val_accuracy: 0.8650\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f27edefb370>"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    }
  ]
}